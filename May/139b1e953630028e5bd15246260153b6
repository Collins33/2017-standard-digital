&nbsp; Facebook said Wednesday it is hiring an extra 3,000 staff to root out violent content as the social media giant faces scrutiny for a series of killings and suicides broadcast on its platform. &quot;If we&#39;re going to build a safe community, we need to respond quickly,&quot; chief executive Mark Zuckerberg said on his Facebook page. &quot;We&#39;re working to make these videos easier to report so we can take the right action sooner -- whether that&#39;s responding quickly when someone needs help or taking a post down.&quot; The 3,000 new recruits, added over the coming year, will increase by two thirds the size of Facebook&#39;s community operations team, which currently numbers 4,500. Zuckerberg&#39;s announcement came a week after a 20-year-old Thai man broadcast live video on the world&#39;s most popular social media platform, showing him killing his baby daughter before committing suicide. ALSO READ: Police identify possible poll violence hot spots The previous week, a US man dubbed the &quot;Facebook Killer&quot; fatally shot himself after three days of a frantic nationwide manhunt. &quot;We&#39;ve seen people hurting themselves and others on Facebook -- either live or in video posted later,&quot; Zuckerberg said. &quot;It&#39;s heartbreaking, and I&#39;ve been reflecting on how we can do better for our community.&quot; The additional reviewers will &quot;help us get better at removing things we don&#39;t allow on Facebook like hate speech and child exploitation,&quot; he said. &quot;And we&#39;ll keep working with local community groups and law enforcement who are in the best position to help someone if they need it -- either because they&#39;re about to harm themselves, or because they&#39;re in danger from someone else.&quot; Critics say the social network has been too slow to react to online violence, and questioned whether Facebook Live -- a strategic area of development for the company -- should be disabled, after several cases in which it was used to broadcast rapes. Zuckerberg said Facebook has been working on better technology that can identify violent or inappropriate content -- and that its efforts to screen for acts of violence appeared to be paying off. &quot;Just last week, we got a report that someone on Live was considering suicide,&quot; he said. ALSO READ: Police identify possible poll violence hot spots &quot;We immediately reached out to law enforcement, and they were able to prevent him from hurting himself. In other cases, we weren&#39;t so fortunate.&quot;